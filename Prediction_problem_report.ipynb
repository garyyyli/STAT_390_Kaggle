{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2d08f12d",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Prediction problems: Report\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "    html-math-method: mathml \n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d691ac",
   "metadata": {},
   "source": [
    "## A.1) Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaaaea5",
   "metadata": {},
   "source": [
    "Mention the data cleaning steps taken to prepare your data for developing the model. This may include imputing missing values, dealing with outliers, combining levels of categorical variable(s), etc."
   ]
  },
  {
   "cell_type": "raw",
   "id": "6fb1163e",
   "metadata": {},
   "source": [
    "# Load packages\n",
    "library(caret)\n",
    "library(xgboost)\n",
    "library(readr)\n",
    "library(caretEnsemble)\n",
    "library(e1071)\n",
    "library(SuperLearner)\n",
    "library(randomForest)\n",
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(stringr)\n",
    "library(knitr)\n",
    "library(modelr)\n",
    "library(skimr)\n",
    "library(hardhat)\n",
    "library(naniar)#  Set seeds\n",
    "set.seed(2023)\n",
    "\n",
    "# Load data\n",
    "train <- read_csv(\"train.csv\")\n",
    "test <- read_csv(\"test.csv\")\n",
    "\n",
    "# Prepare the data\n",
    "missing_values <- is.na(train)\n",
    "train[missing_values] <- 0\n",
    "\n",
    "missing_values_t <- is.na(test)\n",
    "test[missing_values_t] <- 0\n",
    "\n",
    "# Remove constant or zero columns\n",
    "constant_cols <- apply(train, 2, function(x) length(unique(x)) == 1)\n",
    "zero_cols <- apply(train, 2, function(x) all(x == 0))\n",
    "\n",
    "constant_cols_t <- apply(test, 2, function(x) length(unique(x)) == 1)\n",
    "zero_cols_t <- apply(test, 2, function(x) all(x == 0))\n",
    "train <- train[, !(constant_cols | zero_cols)]\n",
    "test <- test[, !(constant_cols_t | zero_cols_t)]\n",
    "\n",
    "\n",
    "# Separate the target variable\n",
    "train_target <- train$y\n",
    "# Perform PCA\n",
    "pca <- prcomp(train[, -ncol(train)], scale. = TRUE)\n",
    "train_pca <- predict(pca, newdata = train[, -ncol(train)])\n",
    "test_pca <- predict(pca, newdata = train[, -ncol(train)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1608757",
   "metadata": {},
   "source": [
    "## A.2) Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761fff41",
   "metadata": {},
   "source": [
    "Mention any major insights you obtained from the data, which you used to develop the model. PLease put your code or visualizations here if needed.\n",
    "\n",
    "- Insight 1: Correlation analysis. By examining the correlation between variables, I find many of them are correlated with each other, which make me think about perform a pca to capture the most significant variance in the data.\n",
    "- Insight 2: Missing values analysis. There's a lot of missing values in the data. However, they are not very significant given the large number of observations.\n",
    "- Insight 3: Data distribution. The distribution of variables indicate a log transformation might be helpful.\n",
    "- Insight 4: Feature importance. Certain variables may have a stronger impact on the target variable compared to others. However, in this data, the RF feature importance doesn't give any significant result.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1865526f",
   "metadata": {},
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix <- cor(train)\n",
    "\n",
    "# Missing data summary\n",
    "missingness_summary <- naniar::vis_miss(train)\n",
    "\n",
    "# Histogram\n",
    "hist(train$variable)\n",
    "\n",
    "# Random Forest feature importance\n",
    "model_rf <- randomForest(train_target ~ ., data = train)\n",
    "var_importance <- importance(model_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43d8af",
   "metadata": {},
   "source": [
    "## A.3) Feature selection/reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc78b0",
   "metadata": {},
   "source": [
    "Mention the steps for feature selection/reduction. PLease put your code or visualizations here if needed.\n",
    "\n",
    "1. Perform PCA: Apply PCA to the dataset to reduce the dimensionality and capture the underlying patterns in the data. In the provided code snippet, `prcomp()` function is used to perform PCA on `train_2` dataset with scaling enabled (`scale. = TRUE`).\n",
    "\n",
    "2. Summary of PCA: Obtain the summary of the PCA results to understand the variance explained by each principal component. This can be done using the `summary()` function on the PCA object (`pca`).\n",
    "\n",
    "3. Variance explained: Calculate the proportion of variance explained by each principal component. In the given code, the square of the standard deviation of each principal component is divided by the sum of squared standard deviations to get the variance explained.\n",
    "\n",
    "4. Scree plot: Create a scree plot to visualize the variance explained by each principal component. The code provided uses the `plot()` function to plot the variance explained against the principal component number.\n",
    "\n",
    "5. Select a subset of principal components: Choose a subset of the principal components based on the desired number of components (`num_components`). In the code, the first `num_components` principal components are selected using indexing (`pca$x[, 1:num_components]`), and they are assigned to the `selected_components` variable.\n",
    "\n",
    "These steps help in feature selection/reduction by identifying the principal components that capture the most significant variance in the data. The scree plot and variance explained information assist in determining the optimal number of principal components to retain."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a6613de",
   "metadata": {},
   "source": [
    "# Perform PCA\n",
    "pca <- prcomp(train_2, scale. = TRUE)\n",
    "summary(pca)\n",
    "\n",
    "eigs <- pca$sdev^2\n",
    "eigs[1] / sum(eigs)\n",
    "cumsum(eigs)/sum(eigs)\n",
    "\n",
    "# Access the principal components\n",
    "principal_components <- pca$x\n",
    "\n",
    "# Access the proportion of variance explained\n",
    "variance_explained <- pca$sdev^2 / sum(pca$sdev^2)\n",
    "\n",
    "# Create a scree plot\n",
    "scree_plot <- plot(1:length(variance_explained), variance_explained, \n",
    "                   type = \"b\", xlab = \"Principal Component\", \n",
    "                   ylab = \"Proportion of Variance Explained\",\n",
    "                   main = \"Scree Plot\")\n",
    "\n",
    "\n",
    "# Select a subset of principal components\n",
    "num_components <- 100\n",
    "selected_components <- pca$x[, 1:num_components]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd58e2ad",
   "metadata": {},
   "source": [
    "## A.4) Developing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72c68",
   "metadata": {},
   "source": [
    "Mention the logical sequence of steps taken to obtain the final model. \n",
    "\n",
    "First, define the models. In this step, you define and train each individual model. Here, Model 1 represents model_glm, Model 2 represents model_xgb, and so on. The models can be different algorithms or variations of the same algorithm with different hyperparameters.\n",
    "\n",
    "Second, make predictions on the test set. Using the trained models, you make predictions on the test set. For each model, you use the corresponding test data (e.g., test_pca) to generate predictions (pred_glm, pred_xgb, pred_svm).\n",
    "\n",
    "Third, apply ensemble predictions. Combine the predictions from the individual models to create an ensemble prediction. In this case, the ensemble prediction is calculated as the average of the predictions from all the models: (pred_glm + pred_xgb + pred_svm) / 3.\n",
    "\n",
    "Last, output the predictions. Save the ensemble predictions to a CSV file. In the given code snippet, the predictions are stored in a data frame with a single column (y), and then the data frame is written to a CSV file named \"ensemble_predictions.csv\" using the write_csv() function."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f1521d7",
   "metadata": {},
   "source": [
    "# Define the models\n",
    "model_glm <- glm(train_target ~ ., data = as.data.frame(train_pca), family = gaussian(link = \"identity\"))\n",
    "model_xgb <- xgboost(data = as.matrix(train_pca), label = train_target, nrounds = 100, max_depth = 3, eta = 0.1)\n",
    "model_svm <- svm(train_target ~ ., data = as.data.frame(train_pca), kernel = \"radial\")\n",
    "\n",
    "# Make predictions on the test set\n",
    "pred_glm <- predict(model_glm, newdata = as.data.frame(test_pca))\n",
    "pred_xgb <- predict(model_xgb, newdata = as.matrix(test_pca))\n",
    "pred_svm <- predict(model_svm, newdata = as.data.frame(test_pca))\n",
    "\n",
    "# Ensemble predictions\n",
    "ensemble_pred <- (pred_glm + pred_xgb + pred_svm) / 3\n",
    "\n",
    "\n",
    "# Output the predictions to a CSV file\n",
    "write_csv(data.frame(y = ensemble_pred), \"ensemble_predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c148744c",
   "metadata": {},
   "source": [
    "## A.5) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef6e03",
   "metadata": {},
   "source": [
    "Please provide details of the models/approaches you attempted but encountered challenges or unfavorable outcomes. If feasible, kindly explain the reasons behind their ineffectiveness or lack of success. Additionally, highlight the significant challenges or issues you encountered during the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62f117d",
   "metadata": {},
   "source": [
    "Initially, I attempted to use a Poisson model for regression, but it did not yield favorable results. Upon reviewing the code, I realized that the selection of the number of features for PCA might be the potential issue. Instead of choosing only a few variables that captured the most significant variance, I decided to increase the number of selected features to explain a larger portion of the data. Initially, this approach showed some improvement as it slightly reduced the RMSE score, but it still had limitations.\n",
    "\n",
    "To address these limitations, I decided to explore alternative models such as KNN (K-Nearest Neighbors) and RF (Random Forest). These models offer different regression techniques and may potentially provide better results. By trying different algorithms, my goal is to enhance the accuracy and overall performance of the regression model. These lead me to think about using an ensemble model that can offer the flexibility to combine different types of models, such as decision trees, neural networks, or support vector machines. By leveraging the strengths of each model type, the ensemble can benefit from their complementary characteristics, resulting in improved overall performance. The ensemble model does achieve higher predictive accuracy compared to individual models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7b917",
   "metadata": {},
   "source": [
    "## A.6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0af5e",
   "metadata": {},
   "source": [
    "* Do you feel that you gain valuable experience, skills, and/or knowledge? If yes, please explain what they were. If no, please explain.\n",
    "* What are things you liked/disliked about the project and/or work on the project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f2a069",
   "metadata": {},
   "source": [
    "Yes, I gained a lot of valuable experience from participating in this Kaggle data competition. Throughout the project, I applied a wide range of data analysis techniques and enhanced my skills in various areas such as data preprocessing, feature engineering, model selection, and evaluation. I faced challenges at every stage of the competition, starting from data cleaning and preprocessing, to making informed decisions on feature selection, and finally developing models. One of the key aspects of my learning experience was the iterative nature of the competition. I constantly reflected on the performance of my models, analyzing the results and seeking opportunities for improvement. This process allowed me to think critically about the shortcomings of my initial approaches and encouraged me to explore alternative solutions. I tried different algorithms, adjusted hyperparameters, and experimented with various feature engineering techniques to enhance the predictive power of my models. By actively engaging in this iterative process, I not only refined my technical skills but also developed a deeper understanding of the strengths and limitations of different modeling approaches. It taught me the importance of critically evaluating model performance and continually refining my strategies to achieve better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8885bf",
   "metadata": {},
   "source": [
    "One of the aspects I particularly enjoyed about this project was the iterative process of building on previous progress and continuously striving to improve the regression model to achieve the best possible score. Throughout the competition, there were instances where the results were unfavorable or not as expected, and it could be disheartening. However, I found the process of reflection and analysis after each step to be incredibly valuable.\n",
    "\n",
    "Taking the time to reflect on the model's performance, understanding the reasons behind any setbacks or suboptimal results, and identifying areas for improvement allowed me to fine-tune my approach. It was through this continuous learning and adjustment process that I made progress and saw tangible improvements in the regression model. While encountering setbacks can be discouraging, the process of pushing through and persevering in the face of challenges was both rewarding and fulfilling. It taught me the importance of resilience and the value of persistence in achieving better outcomes. This project helped me develop a growth mindset, where I saw setbacks as opportunities for learning and improvement, rather than obstacles to success.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
